?pt
install.packages(c("bibtex", "boot", "digest", "gWidgetsRGtk2", "highr", "httr", "jsonlite", "knitcitations", "knitr", "manipulate", "mime", "minqa", "RColorBrewer", "Rcpp", "RcppEigen", "RCurl", "RefManageR", "rjson", "seqinr"))
install.packages("RiboSort")
install.packages("C:/Users/Owner/Downloads/RiboSort_1.1.1.tar.gz", repos = NULL, type = "source")
install.packages("C:/Users/Owner/Downloads/RiboSort_1.1.tar.gz", repos = NULL, type = "source")
install.packages("RiboSort")
install.packages("lrgpr")
install.packages("C:/Users/Owner/Downloads/lrgpr_0.1.5.tar.gz", repos = NULL, type = "source")
install.packages("RcppGSL")
install.packages("RcppProgress")
install.packages("formula.tools")
install.packages("BH")
install.packages("doParallel")
install.packages("bigmemory")
install.packages("bigmemory.sri")
install.packages("aod")
install.packages("C:/Users/Owner/Downloads/lrgpr_0.1.5.tar.gz", repos = NULL, type = "source")
install.packages("RUnit")
install.packages("bigmemory")
install.packages("C:/Users/Owner/Downloads/bigmemory_4.4.6.tar.gz", repos = NULL, type = "source")
uninstall(rPlant)
uninstall.packages("rPlant")
remove.packages("rPlant")
source("http://bioconductor.org/biocLite.R")
detach("package:BiocInstaller", unload=TRUE)
biocLite("hdf5")
library("BiocInstaller", lib.loc="~/R/win-library/3.1")
biocLite("hdf5")
biocLite("hdf5")
update.packages("MASS")
install.packages("nlme")
install.packages("mgcv")
install.packages("Matrix")
install.packages("codetools")
install.packages("foreign")
biocLite("hdf5")
# Functions for making simulation data sets
NoPopStructure <- function(my.mu=0.5, my.s2=0.3, places=c(1212, 2479, 1048, 417, 1527, 1018, 2675, 1734),
effects=c(2, 2, 3, 3, 5, 5, 7, 7), pedfile='/Users/dustin/Desktop/simulation10.ped', write.ped=TRUE,
write.dest='~/Desktop/DustinsSimulation.ped') {
ped <- read.table(file=pedfile, header=FALSE)
n <- nrow(ped)
snps <- length(places)
mu <- my.mu
e <- rnorm(n, 0, my.s2)
g <- matrix(rep(NA, snps), nrow=snps, ncol=n)
for (i in 1:n) {
associated.SNPS <- ped[i, places+7]
associated.SNPS <- ifelse(associated.SNPS == 'A', 1, 0)
g[,i] <- associated.SNPS * effects
}
y <- matrix(nrow=n, ncol=1)
for (j in 1:n) {
y[j] <- mu + e[j] + sum(g[,j])
}
if (write.ped==TRUE) {
new.ped <- ped
new.ped[,6] <- y
write.table(x=new.ped, file=write.dest, quote=FALSE, row.names=FALSE, col.names=FALSE)
}
return(y)
}
NoPopStructure()
library(MASS)
data(Aids2)
data<-data(Aids2)
area()
?sciplot
install.packages("sciplot")
install.packages("sciplot")
?sciplot
??sciplot
install.packages("markdown")
?commandArgs
commandArgs()
??getopt
median.test <- function(x, y){
z <- c(x, y)
g <- rep(1:2, c(length(x), length(y)))
m <- median(z)
fisher.test(z < m, g)$p.value
}
for (i in Qnames){
print(i)
p<-ks.test(dataEng[[i]],dataChi[[i]], exact=F)$p.value
if (p < 0.05){
print(p)
}
}
?grep
x<-matrix(1:10, nrow=2)
print(x)
df<-data.frame(x=rnorm(10), y=rnorm(10))
mdl<-lm(y~x, data=df)
mdl
print(mdl)
str(mdl)
unclass(mdl)
f<-function(x){y <- z+1; z <- y*2;z}
f(1)
debug(f)
f(1)
?prcomp
x<-matrix(rnorm(10000*500), nrow=10000, ncol=500)
f<-function(x){ t(x) %*% x}
g<-function(x) crossprod(x)
library(microbenchmark)
benchmark(f, g)
install.packages(microbenchmark)
install.packages("microbenchmark")
?rbenchmark
??benchmark
??rbenchmark
install.packages(rbenchmark)
install.packages("rbenchmark")
library(rbenchmark)
benchmark(f, g)
rbenchmark(f, g)
33*2*3
?cbind
?mapply
?assign
?new
data(trees)
View(trees)
?length
??getopt
library(sciplot)
?showMethods
showMethods(lineplot.CI)
??as.
?as.logical
pvals<-c(0.084,0.0542,0.0146,0.0472,0.0072,0.0002,0.805,0.2326,0.5392,0.1612,0.0002,0.499,0.6442,0.235,0.0006,0.314,0.3428,0.0046,0.1718,0.014,0.005)
p.adjust(pvals,adjust="holm")
p.adjust(pvals,method="holm")
?rgamma
rgamma(20, shape=20, scale=1)
hist(rgamm(20,shape=20,scale=1))
hist(rgamma(20,shape=20,scale=1))
hist(rgamma(200,shape=20,scale=1))
hist(rgamma(2000,shape=20,scale=1))
setwd("~/Metagenomic Data")
source("TwoStage_Package_Code.R")
#Read in data
ECID<-read.table("ECIDs.cts_75.Mapping.padded.main.cumulative.summary_table.tsv",sep="\t",quote="",header=TRUE)
ProcID<-read.table("GOProcIDs.cts_75.Mapping.padded.main.cumulative.summary_table.tsv",sep="\t",quote="",header=TRUE)
FuncID<-read.table("GOFuncIDs.cts_75.Mapping.padded.main.cumulative.summary_table.tsv",sep="\t",quote="",header=TRUE)
PFamID<-read.table("PFamIDs.cts_75.Mapping.padded.main.cumulative.summary_table.tsv",sep="\t",quote="",header=TRUE)
TIGRID<-read.table("TIGRFamIDs.cts_75.Mapping.padded.main.cumulative.summary_table.tsv",sep="\t",quote="",header=TRUE)
Phyllo<-read.table("Phyllo_Genus.cts_75.combined.main.summary_table.xls",sep="\t",quote="",header=T)
factors<-read.csv("phyllo_factors.csv",header=T)[-c(9:12),]
datasets<-list(ECID,ProcID,FuncID,PFamID,TIGRID,Phyllo)
remove(ECID,ProcID,FuncID,PFamID,TIGRID,Phyllo) #Dump old variables to save memory
#Grab max control values
CheckControls<-function(data){
controls<-data[9:12,2:length(data)]
A<-apply(controls,2,max)
return(A)
}
#Clean data by subtracting max control value from each (also takes out control rows)
AdjustData<-function(data){
data.max<-CheckControls(data)
newdata<-data[-c(9:12),]
for (i in 2:length(newdata)){
newdata[i]<-newdata[i]-data.max[i-1]
newdata[i][newdata[i]<0]<-0
}
return(newdata)
}
datasets<-lapply(datasets,AdjustData)
#Determine which observations correspond to which cities
CA.obs<-which(factors$city=="CA")
CA.group<-factors[CA.obs,]
HF.obs<-which(factors$city=="HF")
HF.group<-factors[HF.obs,]
DE.obs<-which(factors$city=="DE")
DE.group<-factors[DE.obs,]
Citylist<-list(CA.group,HF.group,DE.group)
for (i in 1:length(datasets)){
datasets[[i]]$Total<-NULL
}
#Transpose and further manipulate data as needed
datasets<-lapply(datasets,t)
newdat<-list()
#Need to re-read the transposed datasets so that the sample IDs are recognized as headers
for (i in seq_along(datasets)){
rownames(datasets[[i]])[1]<-""
filename<-paste(i,".csv",sep="")
write.table(datasets[[i]], file=paste("dataset",filename, sep="-"),sep=",",quote=TRUE,row.names=TRUE,col.names=FALSE)
newdat[[i]]<-read.table(paste("dataset",filename,sep="-"),sep=",",header=T)
unlink(paste("dataset",filename,sep="-"))
}
#Subset data based on city (for some reason, indices are one off, but this is easily fixed)
Citysplitter<-function(data){
list1<-list()
list1[[length(list1)+1]]<-data[CA.obs+1]
list1[[length(list1)+1]]<-data[DE.obs+1]
list1[[length(list1)+1]]<-data[HF.obs+1]
list1<-lapply(list1,function(y) cbind(data$X,y))
return(list1)
}
remove(datasets)
uberlist<-lapply(newdat,Citysplitter)
#NOTE: Uberlist goes in the following order for cities: CA, DE, HF
row.names(CA.group)<-row.names(HF.group)<-row.names(DE.group)<-NULL
CA.group$city<-HF.group$city<-DE.group$city<-NULL
#Depending on the dataset you wish to run (either with subsets or without), you should run one of the following loops:
#This first loop is for the dataset with subsets based on city
readFiles <- function(dir) {
setwd(dir)
files <- (Sys.glob("*.csv"))
listOfFiles <- lapply(files, function(x) read.table(x, sep=",", header=TRUE))
return(listOfFiles)
}
effectrank<-function(data){
data$effect<-data$mean_group1-data$mean_group2
data$rank<-rank(data$effect)
}
analyses<-readFiles("~/Metagenomic Data/Full Outputs")
sapply(analyses,effectrank)
lapply(analyses,effectrank)
effectrank(analyses[[1]])
View(analyses[[1]])
effectrank<-function(data){
data$effect<-NA
data$effect<-data$mean_group1-data$mean_group2
data$rank<-NA
data$rank<-rank(data$effect)
}
effectrank(analyses[[1]])
View(analyses[[1]])
analyses[[1]]$effect<-analyses[[1]]$mean_group1-analyses[[2]]$mean_group2
analyses[[1]]$effect<-analyses[[1]]$mean_group1-analyses[[1]]$mean_group2
View(analyses[[1]])
analyses[[1]]$rank<-rank(analyses[[1]]$effect)
View(analyses[[1]])
plot(analyses[[1]]$mean_group1, analyses[[1]]$effect)
par(new=TRUE)
plot(analyses[[1]]$mean_group1, analyses[[1]]$mean_group2)
plot(analyses[[1]]$mean_group1, analyses[[1]]$effect)
par(new=TRUE)
plot(analyses[[1]]$mean_group1, analyses[[1]]$mean_group2, type="l",axes=FALSE, xlab="",ylab="")
plot(analyses[[1]]$mean_group1, analyses[[1]]$mean_group2,axes=FALSE, xlab="",ylab="")
plot(analyses[[1]]$mean_group1, analyses[[1]]$effect)
par(new=TRUE)
plot(analyses[[1]]$mean_group1, analyses[[1]]$mean_group2,axes=FALSE, xlab="",ylab="")
plot(analyses[[1]]$mean_group1, analyses[[1]]$mean_group2,axes=FALSE, xlab="",ylab="mean2")
plot(analyses[[1]]$mean_group1, analyses[[1]]$effect)
par(new=TRUE)
plot(analyses[[1]]$mean_group1, analyses[[1]]$mean_group2,axes=FALSE, xlab="",ylab="mean2")
axis(side=4, at=pretty(range(analyses[[1]]$mean_group2)))
mtext("analyses[[1]]$mean_group2, side=4, line=3)
""
mtext("analyses[[1]]$mean_group2, side=4, line=3))
mtext("analyses[[1]]$mean_group2", side=4, line=3)
mtext("analyses[[1]]$mean_group2", side=1, line=3)
mtext("analyses[[1]]$mean_group2", side=2, line=3)
mtext("analyses[[1]]$mean_group2", side=3, line=3)
mtext("analyses[[1]]$mean_group2", side=4, line=3)
mtext("analyses[[1]]$mean_group2", side=4, line=1)
plot(analyses[[1]]$mean_group1, analyses[[1]]$effect)
axis(side=4, at=range(analyses[[1]]$mean_group2), labels=TRUE)
axis(side=4, line=3, at=range(analyses[[1]]$mean_group2), labels=TRUE)
install.packages(gtable)
install.packages("gtable")
install.packages("grid")
library(ggplot2)
library(gtable)
library(grid)
library(q)
grid.newpage()
q<-analyses[[1]]
p1<-ggplot(q, aes(q$mean_group1, q$effect) + theme_bw())
p1<-ggplot(q, aes(x=q$mean_group1, y=q$effect) + theme_bw())
p1<-ggplot(q, aes(x=q$mean_group1, y=q$effect))
p1
p2<-ggplot(q, aes(x=q$mean_group1, y=q$mean_group2))
g1<-ggplot_gtable(ggplot_build(p1))
g1 <- ggplot_gtable(ggplot_build(p1))
View(factors)
for (i in 1:length(newdat)){
newdat[[i]][,19]<-NA
colnames(newdat[[i]])[19]<-"PHYLLO30"
newdat[[i]]$PHYLLO30<-round((newdat[[i]]$PHYLLO28+newdat[[i]]$PHYLLO29)/2)
}
#Add new drought phenotype entry to HF group
Sample_ID<-c(as.character(HF.group$Sample_ID),"PHYLLO30")
HF.group$Sample_ID<-factor(Sample_ID)
HF.group[,1]
HF.group[1,]
HF.group[5,]
HF.group[,2]
class(HF.group[,2])
HF.group[6,]<-c(factor("PHYLLO30"),factor("drought"))
View(newdat[[2]])
Sample_ID<-c(as.character(HF.group$Sample_ID),"PHYLLO30")
treatment<-c(as.character(HF.group$treatment),"drought")
HF.group[,2]
HF.group[,1:2]<-c(factor(Sample_ID),factor(treatment)
)
View(HF.group)
View(DE.group)
View(HF.group)
HF.group<-factors[HF.obs,]
row.names(CA.group)<-row.names(HF.group)<-row.names(DE.group)<-NULL
CA.group$city<-HF.group$city<-DE.group$city<-NULL
Sample_ID<-c(as.character(HF.group$Sample_ID),"PHYLLO30")
HF.group$Sample_ID<-factor(Sample_ID)
HF.group$Sample_ID<-as.factor(Sample_ID)
HF.group[6,]<-NA
HF.group$Sample_ID<-as.factor(Sample_ID)
View(HF.group)
HF.group$treatment[6]
HF.group$treatment[6]<-as.factor("drought")
HF.group$treatment[6]
HF.group$treatment[5]
View(HF.group)
HF.group[6,]<-NA
HF.group[6,]<-c(as.factor("PHYLLO30"),as.factor("drought"))
HF.group[6,]<-NA
HF.group$Sample_ID[6]<-as.factor("PHYLLO30")
HF.group$treatment[6]<-as.factor("drought")
View(factors)
colnames(factors)
factor30<-c(as.factor("PHYLLO30"),as.factor("HF"),as.factor("drought"))
rbind(factors, factor30)
factors[21,]
factors[20,]
View(factors)
factors[17,]
factors[18,]
factors$Sample_ID[18]
factors$Sample_ID[17]
HF.group[6,]<-factors[18,]<-NA
HF.group$Sample_ID[6]<-factors$Sample_ID[18]<-as.factor("PHYLLO30")
HF.group$treatment[6]<-factors$treatment[18]<-as.factor("drought")
View(factors)
factors<-read.csv("phyllo_factors.csv",header=T)[-c(9:12),]
setwd("~/Metagenomic Data")
factors<-read.csv("phyllo_factors.csv",header=T)[-c(9:12),]
HF.obs<-which(factors$city=="HF")
HF.group<-factors[HF.obs,]
CA.group$city<-HF.group$city<-DE.group$city<-NULL
HF.group[6,]<-factors[22,]<-NA
HF.group$Sample_ID[6]<-factors$Sample_ID[22]<-as.factor("PHYLLO30")
HF.group$treatment[6]<-factors$treatment[22]<-as.factor("drought")
View(factors)
factors<-read.csv("phyllo_factors.csv",header=T)[-c(9:12),]
HF.group[6,]<-factors[18,]<-NA
HF.group$treatment[6]<-factors$treatment[22]<-as.factor("drought")
HF.group$treatment[6]<-factors$treatment[18]<-as.factor("drought")
HF.group$Sample_ID[6]<-factors$Sample_ID[22]<-factor("PHYLLO30")
HF.group$Sample_ID[6]<-factors$Sample_ID[18]<-factor("PHYLLO30")
View(factors)
HF.group[6,]<-factors[18,]<-NA
Samples<-c(as.character(factors$Sample_ID),"PHYLLO30")
Samples.HF<-c(as.character(HF.group$Sample_ID),"PHYLLO30")
factors$Sample_ID<-as.factor(Samples)
HF.group$Sample_ID<-as.factor(Samples.HF)
HF.group[6,]<-factors[18,]<-NA
Samples<-c(as.character(factors$Sample_ID[1:17]),"PHYLLO30")
Samples.HF<-c(as.character(HF.group$Sample_ID[1:5]),"PHYLLO30")
factors$Sample_ID<-as.factor(Samples)
HF.group$Sample_ID<-as.factor(Samples.HF)
View(HF.group)
View(factors)
HF.group$treatment[6]<-factors$treatment[18]<-as.factor("drought")
View(factors)
View(HF.group)
#Subset data based on city (for some reason, indices are one off, but this is easily fixed)
Citysplitter<-function(data){
list1<-list()
list1[[length(list1)+1]]<-data[CA.obs+1]
list1[[length(list1)+1]]<-data[DE.obs+1]
list1[[length(list1)+1]]<-data[HF.obs+1]
list1<-lapply(list1,function(y) cbind(data$X,y))
return(list1)
}
uberlist<-lapply(newdat,Citysplitter)
#NOTE: Uberlist goes in the following order for cities: CA, DE, HF
row.names(CA.group)<-row.names(HF.group)<-row.names(DE.group)<-NULL
CA.group$city<-HF.group$city<-DE.group$city<-NULL
#Depending on the dataset you wish to run (either with subsets or without), you should run one of the following loops:
#This first loop is for the dataset with subsets based on city
try(TwoStage_Package(uberlist[[1]][[3]],HF.group,paste("sigtest",".csv",sep="-"),1))
View(uberlist[[1]][[3]])
newdat[[1]]
newdat[[1]]$PHYLLO30
try(TwoStage_Package(newdat[[k]],factors,paste("sigtest",100,"csv",sep="."),1))
try(TwoStage_Package(newdat[[1]],factors,paste("sigtest",100,"csv",sep="."),1))
View(newdat[[1]])
is.na(newdat[[1]]$PHYLLO30)
rownames(factors)<-factors$city<-NULL
try(TwoStage_Package(newdat[[1]],factors,paste("sigtest",100,"csv",sep="."),1))
try(TwoStage_Package(uberlist[[1]][[3]],HF.group,paste("sigtest",".csv",sep="-"),1))
try(TwoStage_Package(newdat[[3]],factors,paste("sigtest",300,"csv",sep="."),1))
HF.obs<-c(HF.obs,18)
setwd("~/Metagenomic Data")
source("TwoStage_Package_Code.R")
#Read in data
ECID<-read.table("ECIDs.cts_75.Mapping.padded.main.cumulative.summary_table.tsv",sep="\t",quote="",header=TRUE)
ProcID<-read.table("GOProcIDs.cts_75.Mapping.padded.main.cumulative.summary_table.tsv",sep="\t",quote="",header=TRUE)
FuncID<-read.table("GOFuncIDs.cts_75.Mapping.padded.main.cumulative.summary_table.tsv",sep="\t",quote="",header=TRUE)
PFamID<-read.table("PFamIDs.cts_75.Mapping.padded.main.cumulative.summary_table.tsv",sep="\t",quote="",header=TRUE)
TIGRID<-read.table("TIGRFamIDs.cts_75.Mapping.padded.main.cumulative.summary_table.tsv",sep="\t",quote="",header=TRUE)
Phyllo<-read.table("Phyllo_Genus.cts_75.combined.main.summary_table.xls",sep="\t",quote="",header=T)
factors<-read.csv("phyllo_factors.csv",header=T)[-c(9:12),]
datasets<-list(ECID,ProcID,FuncID,PFamID,TIGRID,Phyllo)
remove(ECID,ProcID,FuncID,PFamID,TIGRID,Phyllo) #Dump old variables to save memory
#Grab max control values
CheckControls<-function(data){
controls<-data[9:12,2:length(data)]
A<-apply(controls,2,max)
return(A)
}
#Clean data by subtracting max control value from each (also takes out control rows)
AdjustData<-function(data){
data.max<-CheckControls(data)
newdata<-data[-c(9:12),]
for (i in 2:length(newdata)){
newdata[i]<-newdata[i]-data.max[i-1]
newdata[i][newdata[i]<0]<-0
}
return(newdata)
}
datasets<-lapply(datasets,AdjustData)
#Determine which observations correspond to which cities
CA.obs<-which(factors$city=="CA")
CA.group<-factors[CA.obs,]
HF.obs<-which(factors$city=="HF")
HF.group<-factors[HF.obs,]
DE.obs<-which(factors$city=="DE")
DE.group<-factors[DE.obs,]
Citylist<-list(CA.group,HF.group,DE.group)
for (i in 1:length(datasets)){
datasets[[i]]$Total<-NULL
}
#Transpose and further manipulate data as needed
datasets<-lapply(datasets,t)
newdat<-list()
#Need to re-read the transposed datasets so that the sample IDs are recognized as headers
for (i in seq_along(datasets)){
rownames(datasets[[i]])[1]<-""
filename<-paste(i,".csv",sep="")
write.table(datasets[[i]], file=paste("dataset",filename, sep="-"),sep=",",quote=TRUE,row.names=TRUE,col.names=FALSE)
newdat[[i]]<-read.table(paste("dataset",filename,sep="-"),sep=",",header=T)
unlink(paste("dataset",filename,sep="-"))
}
remove(datasets)
for (i in 1:length(newdat)){
newdat[[i]][,19]<-NA
colnames(newdat[[i]])[19]<-"PHYLLO30"
newdat[[i]]$PHYLLO30<-round((newdat[[i]]$PHYLLO28+newdat[[i]]$PHYLLO29)/2)
}
HF.obs<-c(HF.obs,18)
HF.group[6,]<-factors[18,]<-NA
Samples<-c(as.character(factors$Sample_ID[1:17]),"PHYLLO30")
Samples.HF<-c(as.character(HF.group$Sample_ID[1:5]),"PHYLLO30")
factors$Sample_ID<-as.factor(Samples)
HF.group$Sample_ID<-as.factor(Samples.HF)
HF.group$treatment[6]<-factors$treatment[18]<-as.factor("drought")
Citysplitter<-function(data){
list1<-list()
list1[[length(list1)+1]]<-data[CA.obs+1]
list1[[length(list1)+1]]<-data[DE.obs+1]
list1[[length(list1)+1]]<-data[HF.obs+1]
list1<-lapply(list1,function(y) cbind(data$X,y))
return(list1)
}
uberlist<-lapply(newdat,Citysplitter)
#NOTE: Uberlist goes in the following order for cities: CA, DE, HF
row.names(CA.group)<-row.names(HF.group)<-row.names(DE.group)<-NULL
CA.group$city<-HF.group$city<-DE.group$city<-NULL
#Depending on the dataset you wish to run (either with subsets or without), you should run one of the following loops:
#This first loop is for the dataset with subsets based on city
for (i in 1:length(uberlist)){
for (j in 1:length(uberlist[[1]])){
filename<-paste(i,j,"csv",sep=".")
#Set up group depending on which index j is:
group<-switch(j, CA.group, DE.group, HF.group)
#Some datasets have issues with normalization method, hence switch to method 2
try(TwoStage_Package(uberlist[[i]][[j]],group,paste("sigtest","method2",filename,sep="-"),2))
try(TwoStage_Package(uberlist[[i]][[j]],group,paste("sigtest",filename,sep="-"),1))
print(c(i, j)) #Print the "coordinate" of the dataset so we know which ones specifically produc1e errors or insignificant results
}
}
#This second loop is for analyzing the entire dataset, without accounting for the city
setwd("~/Metagenomic Data/Full Outputs") #Move outputs to new folder
rownames(factors)<-factors$city<-NULL
for (k in 1:length(newdat)){
try(TwoStage_Package(newdat[[k]],factors,paste("sigtest",k,"method2","csv",sep="."),2))
try(TwoStage_Package(newdat[[k]],factors,paste("sigtest",k,"csv",sep="."),1))
print(k)
}
readFiles <- function(dir) {
setwd(dir)
files <- (Sys.glob("*.csv"))
listOfFiles <- lapply(files, function(x) read.table(x, sep=",", header=TRUE))
return(listOfFiles)
}
analyses<-readFiles("~/Metagenomic Data/Full Outputs")
analyses<-readFiles("~/Metagenomic Data/Full Outputs")
?rank()
for (i in 1:length(analyses)){
analyses[[i]]$effect<-analyses[[i]]$mean_group1-analyses[[i]]$mean_group2
analyses[[i]]$rank<-rank(analyses[[i]]$effect, ties.method="average")
}
View(analyses[[1]])
View(analyses[[1]])
View(analyses[[2]])
View(analyses[[3]])
cor(analyses[[1]]$p.adj, abs(analyses[[1]]$effect))
